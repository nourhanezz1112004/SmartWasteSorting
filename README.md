# Smart Waste Sorting System (Python GUI Simulation)

## Project Idea

**Description:**
The *Smart Waste Sorting System (Python GUI Simulation)* is a vision-based software prototype
that demonstrates how automated waste sorting systems operate using computer vision concepts.
The system uses a real-time camera feed to capture images of waste items, extracts visual
features from each frame, and classifies the waste into categories such as plastic, metal,
organic, or paper.

This project focuses on demonstrating the **AI workflow** used in smart environmental systems
without relying on physical hardware or industrial sensors.
It is designed for educational purposes and smart city awareness applications.

**Objectives:**
* Design an advanced, interactive GUI using Python.
* Integrate a real-time camera feed using OpenCV.
* Extract visual features from captured frames.
* Perform rule-based classification as a foundation for AI systems.
* Demonstrate the inference pipeline used in computer vision applications.

**Scope:**
**In Scope:** GUI design, camera integration, feature extraction, AI-inspired classification,
real-time processing, and documentation.  
**Out of Scope:** Industrial hardware integration and large-scale deployment.

---

## Team Members and Roles

| Team Member    | GitHub Account     | Role                           | Responsibilities                                          |
| -------------- | ------------------ | ------------------------------ | --------------------------------------------------------- |
| Yasmin Mohamed | @yasminelrefaei    | Project Lead / Developer       | GUI design, system architecture, and camera integration   |
| Norhan Mohamed | @nourhanezz1112004 | AI & Documentation Developer   | Feature extraction logic, classification design, testing, and documentation |

---

## Tools and Usage

| Tool/Library            | Purpose                 | Usage Details                                              |
| ----------------------- | ----------------------- | ---------------------------------------------------------- |
| Python                  | Core language           | Implements system logic and application workflow           |
| CustomTkinter           | GUI framework           | Builds the advanced interactive user interface             |
| OpenCV                  | Computer vision library | Captures and processes real-time camera frames             |
| NumPy                   | Numerical processing    | Handles image feature calculations                         |
| Pillow (PIL)            | Image handling          | Converts frames for GUI display                            |
| GitHub                  | Version control         | Manages project versions and collaboration                 |
| VS Code / PyCharm       | IDE                     | Used for development, debugging, and testing               |

---

## 4-Week Plan

### Week 1: Planning and System Design
* **Milestones:** Define project architecture, camera workflow, and GUI layout.
* **Deliverables:** Initial GUI layout and module structure.
* **Assigned:** Yasmin.

### Week 2: Vision & Feature Extraction
* **Milestones:** Integrate camera feed and extract visual features from frames.
* **Deliverables:** Functional camera module with feature extraction.
* **Assigned:** Norhan.

### Week 3: Classification & Integration
* **Milestones:** Implement rule-based classification and connect it to the GUI.
* **Deliverables:** Real-time classification results displayed in the interface.
* **Assigned:** Yasmin & Norhan.

### Week 4: Testing and Finalization
* **Milestones:** Optimize performance, handle runtime errors, and finalize documentation.
* **Deliverables:** Stable application and final README.
* **Assigned:** Yasmin & Norhan.

**Overall Timeline Notes:**  
The final system demonstrates a complete vision-based AI workflow suitable for academic evaluation.

---

### Checklist for detailed tasks

* [x] Design advanced GUI layout
* [x] Implement real-time camera integration
* [x] Extract visual features from frames
* [x] Apply AI-inspired classification logic
* [x] Display real-time prediction results
* [x] Test system stability
* [x] Prepare final documentation

---

## Evaluation Criteria

* **Success Metrics:** Real-time camera operation, correct GUI interaction,
clear classification output, and well-structured system design.
* **Feedback:** Instructor review based on functionality, architecture, and AI concepts.
* **Next Steps:** Integrate deep learning models (CNN) for higher accuracy
and dataset-based training in future versions.


## Evaluation Criteria

* **Success Metrics:** Functional GUI, smooth interaction, logical classification accuracy, and clear design.
* **Feedback:** Weekly mentor reviews and peer testing feedback.
* **Next Steps:** Extend the system with image-based classification using OpenCV or TensorFlow in the future.
